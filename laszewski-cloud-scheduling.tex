%\documentclass[preprint,12pt,3p]{elsarticle}
\documentclass[final,5p,times,twocolumn]{elsarticle}

\usepackage{dtk-logos}
\usepackage{amssymb}
\usepackage{comment}
\usepackage{fullpage}
\usepackage{graphicx}
\usepackage{adjustbox}
\usepackage{todonotes}
\usepackage{multirow}
\usepackage{makecell}

\usepackage{tikz}
\usetikzlibrary{arrows,mindmap,trees,backgrounds,shapes,arrows,positioning,calc,snakes,fit}
\usepgflibrary{decorations.markings}


\usepackage{verbatim}
\usepackage{forest}
\usepackage{hyperref}
\usepackage{adjustbox}

\usetikzlibrary{arrows.meta,shadows}

\newcommand{\ngreen}{bottom color=green!20}
\newcommand{\ngrey}{bottom color=gray!20}
\newcommand{\nred}{bottom color=red!20}
\newcommand{\nwhite}{bottom color=white!20}
\newcommand{\TODO}[1]{\todo[inline]{#1}}
\newcommand{\GVL}[1]{{\begin{blue} #1}}

%\usepackage[linguistics]{forest}
\usepackage{smartdiagram}

\setcounter{secnumdepth}{6}
\setcounter{tocdepth}{6}

\forestset{
  skan tree/.style={
    for tree={
      drop shadow,
      text width=3cm,
      grow'=0,
      rounded corners,
      draw,
      top color=white,
      bottom color=blue!20,
      edge={Latex-},
      child anchor=parent,
      %parent anchor=children,
      anchor=parent,
      tier/.wrap pgfmath arg={tier ##1}{level()},
      s sep+=2.5pt,
      l sep+=2.5pt,
      edge path'={
        (.child anchor) -- ++(-10pt,0) -- (!u.parent anchor)
      },
      node options={ align=center },
    },
    before typesetting nodes={
      for tree={
        content/.wrap value={\strut ##1},
      },
    },
  },
}


\journal{FGCS}

%\makeatletter
%\def\ps@pprintTitle{%
% \let\@oddhead\@empty
% \let\@evenhead\@empty
% \def\@oddfoot{}%
% \let\@evenfoot\@oddfoot}
%\makeatother

\begin{document}

\begin{frontmatter}

\title{Cloud Resource Scheduling Taxonomy}

\author[iu]{Gregor von Laszewski\corref{cor1}}
\address[iu]{{\small $^1$ Intelligent Systems Engineering Dep., Indiana University, Bloomington, IN 47408, USA.}}
\ead{laszewski@gmail.com}
\ead[url]{https://laszewski.github.io/}
\cortext[cor1]{Corresponding author}

\author[punjab]{Rajni Aron}
\address[punjab]{School of Computer Science and Engineering, Lovely Professional University, Punjab, India}


\author[iu]{Geoffrey C. Fox}


\begin{abstract}
The growth and development of scientific applications in the cloud
demands the creation of efficient resource management systems. Due to
the scale of resources, the heterogeneity of services, their
inter-dependencies and unpredictability of load this is a complex
problem. We present a resource scheduling taxonomy that is originating
from our experience in utilizing and managing multi-cloud environments. 
Our study is backed up by a literature review that
targets not only virtual machine, but also container and Function as a
Service frameworks. It justifies our model and provides a an overview
of existing scheduling techniques in cloud computing. As a result this
work can lead a better understanding of scheduling for clouds
in general. The study promotes the vision of a layered scheduling
architecture that will be useful for the implementation of application
and resource-based scheduling frameworks in support of the NIST Big
Data Reference Architecture.

\end{abstract}

\begin{keyword}
  Taxonomy \sep
  Scheduling \sep
  Cloud \sep
  Containers \sep
  HPC in the Cloud \sep
  Virtual Machines \sep
  FaaS \sep
  IaaS \sep
  PaaS
\end{keyword}

\end{frontmatter}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


Cloud computing has emerged as a computing paradigm to solve
large-scale application in many domains including science, e-commerce, 
lifestyle, and many other areas. According to the definition of NIST, 
Cloud
computing is a model for enabling ubiquitous, convenient, on-demand
network access to a shared pool of configurable computing resources
that can be rapidly provisioned and released with minimal management
effort or service provider interaction~\cite{mell2011nist}.

Sustaining efficient resource provisioning and utilization in clouds
is a formidable challenge. Poor resource management results in high
costs that are amplified by long term and dynamic-scalable usage
patterns we see in large scale cloud applications. Hence, scheduling
plays an important role in improving resource utilization providing
the necessary guidance to optimize the allocation of resource.
Consequently, Resource scheduling is an important service of any cloud
framework as it is responsible for orchestrating the resources to both
cloud providers and cloud users in an efficient manner.

We showcase that scheduling in the cloud requires a multi-layered
approach that not only schedules tasks and jobs, but also integrates
provisioning of resources and dynamic adaptation of loads during the
run-time of applications. Information has to be passed between the
various layers that comprise our scheduling architecture for clouds to
guide the optimal placement onto resources. This cloud-based
scheduling models is more comprehensive than previous classical
scheduling approaches as it is conducted on scales and resource pools
that were previously not considered. The scheduling is not only done
on the task, job, and cluster level but integrates the data center and
even regional and global data centers while adding on demand resource
needs. Our study identifies services that assist in the formulation of
the scheduling needs and interfaces for the NIST Big Data Reference
Architecture (NIST-BDRA) \cite{nist-bdra-vol6} and it's interface
definitions currently under development \cite{nist-bdra-vol8}.

The paper is structured as follows. We present first in
Section~\ref{sec:terminology} our general terminology we use throughout
the paper. Next we present in Section ~\ref{sec:taxonomy} our
architecture view and taxonomy that we have derived from our practical
experience with FutureGrid
\cite{las12fg-bookchapter,fox2013futuregrid}, FutureSystem, and
Software such as Cloudmesh \cite{von2014accessing}, Virtual Clusters
\cite{las-comet}, and Rain \cite{las-fg-1295,las10dynamic,las-rain}
while working on multi-hosted heterogeneous cloud frameworks. This
view is backed up by our extensive literature research in Sections
\ref{sec:literature} and our classification based on the taxonomy we
introduced in the previous sections. Lastly, we provide some
concluding remarks in Section~\ref{sec:conclusion}.


\section{General Scheduling Terminology for Clouds}\label{sec:terminology}

We use the following terminology for Cloud computing and Resource scheduling:

\begin{description}

\item[Cloud Computing:] According to the definition of NIST, Cloud computing
  is a model for enabling ubiquitous, convenient, on-demand network
  access to a shared pool of configurable computing resources that can
  be rapidly provisioned and released with minimal management effort
  or service provider interaction~\cite{mell2011nist}.

\item[Cloud Resource:] Is a resource offered by a cloud provider as
  part of the implementation of a cloud application that may use this
  resource.

\item[Cloud Service:] Is a service offered by a cloud provider or
  developed as part of an application utilizing cloud resources and
  exposing the functionality as a service.
  
\item[Cloud Application:] Is an application that uses cloud services
  and resources to target an application providing concrete
  implementations for its instantiation and execution.

\item [Resource Provisioning in the Cloud:] The allocation of the
  resources demanded by users to specific
  applications is called provisioning. 
  
\item [Resource Scheduling in the Cloud:] Resource scheduling in the
  cloud refers to the mapping of resources to fulfill the jobs
  resource requirements.

\end{description}

\section{Scheduling Taxonomy for Clouds}\label{sec:taxonomy}


In this section we introduce our scheduling taxonomy for clouds. Our
taxonomy integrates the classical cloud architecture as defined by
NIST \cite{mell2011nist}. However, as scheduling is conducted with
resources in mind we also focus on aspects to deal with cloud
resources, their physical instantiation and their connectivity while
showcasing their relationship in our taxonomy.

\subsection{Layered scheduling}

The NIST cloud model promotes an easy to understand separation between
infrastructure, platforms and services. This separation motivates a
scheduling taxonomy separated by the different layers in which service
providers and users attempt to place compute, data and other services
in order to optimize the use of the infrastructure as is showcased in
Figure~\ref{F:NIST} while enhancing it with Function as a Service
(FaaS).

\input{graph-layer}

\input{graph-flow.tex}


A platform provider may utilize insights of the infrastructure to
offer to the users an optimized platform placement, while a software
provider or application user may utilize information form the platform
and or the infrastructure to offer scheduling on levels accessible to
them. To facilitate the scheduling on the lower levels, scheduling
information has to be passed along to them to provide enough
information to the provider to integrate scheduling of resources that
are not under direct control by the developer and users.

Thus one strategy to develop scheduling algorithms for the cloud is to
integrate the service boundaries of the layered cloud architecture
into the strategy of conducting a multi-layered scheduling approach in
which we separate concerns as showcased in Figure~\ref{F:multiphase}.
As most recently the FaaS model is introduced by the community we
added it to the figure to indicate that although they are defined by
the user, the functions have well defined resource constraints that
make scheduling decisions on the infrastructure provider level easier.
Hence to optimize usage of the infrastructure, providers have come up
with an easy to use extension to the original NIST model allowing for
better potential of utilizing the infrastructure by scheduling small
well defined functions with limited resource needs.

Certainly the goal of hiding the scheduling decisions between each
layer is still important, but enough information between the layers
needs to be exchanged to facilitate good scheduling decisions on each
of the layers.

When put together, we distinguish several aspects that comprise Cloud
scheduling. This includes metrics, cloud scheduling models, cloud
scheduling challenges, the cloud infrastructure, and algorithms
specifically designed to address clouds as seen in Figure~{F:mindmap}.
These aspects are elaborated in more detail next.

\input{graph-mindmap}

\subsection{Resource Provider Focused Y-Cloud Taxonomy}

To showcase the interaction between the different layers more clearly
we like to refer the reader to the Y-cloud scheduling diagram
introduced by Laszewski in~\cite{las18cloudscheduling-whitepaper}.

In this taxonomy we are concerned about how resources are placed on
physical models and are interconnected with each other to facilitate
scheduling algorithms. Figure~\ref{F:taxonomy} depicts the different
models integrated in the Taxonomy. It includes:

\begin{description}

\item[Physical Model] representing major physical resource layers to
  enable a hierarchical scheduling strategy across multiple data
  centers, data centers, racks, servers, and computing cores.

\item[Resource Model] representing models that the scheduling
  algorithm addresses including containers and functions, virtual
  machines and jobs, virtual clusters, provider managed resources, and
  multi-region provider managed resources.

\item[Connectivity Model] introduces a connectivity between components
  when addressing scheduling. This includes components such as memory,
  processes, connectivity to distributed resources, hyper-graphs to
  formulate hierarchies of provider based resources, and region
  enhanced hyper-graphs. The connectivity model allows us to leverage
  classical scheduling algorithms while applying such models and
  leveraging established or new scheduling algorithms for these
  models.

\end{description}

\input{graph-y}

\subsection{Cloud Scheduling Model}

Now that we have identified the resource provider focused Y-Cloud
taxonomy we can identify some important aspects that govern the
scheduling decisions to effectively use these resources. This includes
metrics that influence the scheduling. Traditional scheduling metrics
and attributes for scheduling algorithms are shown in
Figure~\ref{F:class-metric}. They include typically cost, time, space,
reliability, energy, and security.

% \input{graph-metrics}

When looking into the specifics of these metrics applied to cloud
computing we can easily identify more details for these traditional
metrics that apply to the various infrastructure components that
constitute a cloud including compute, data, energy, quality of
service, and security. We depict some of the major attributes that
influence the scheduling decisions in Figure~\ref{F:class-taxonomy}.
Furthermore each of the attributes in the categories Compute, Data,
Security, Energy, and Quality of service can be combined if not
already included in the specific scheduling attribute. For example in
order to identify scheduling model based on virtual machines,
attributes such as the once in data, energy, QoS, or security may be
introduced in the scheduling decision.

\input{graph-taxonomy}

This information can now be used to define provisioning and service
scheduling as categorized next.

\subsection{Taxonomy of Challenges in Cloud Scheduling}\label{sec:challange}

Some of the obvious characteristics and challenges that are
specifically related to clouds are listed next and are summarized in
Figure~\ref{F:metrics-char} while enhancing the traditional scheduling
challenges we introduced earlier.

\begin{description}

\item [Large scale:] Clouds offer large number of resources to its
  users that need to be optimally utilized under quality of service
  constraints set by providers and users. A cloud involving a plethora
  of resources spanning across the globe is obviously a huge
  infrastructure. The range of functions, tasks, jobs and applications
  need to get catered at any point of time too can be in large scale.
  Handling them in such scale requires efficient resource management.
  As such, scheduling becomes a complex endeavour. Rather a complex,
  dynamic and multi-faceted scheduling is necessary.
            
\item [Dynamic nature of clouds:] Due to the dynamic nature of the
  physical cloud infrastructure in which resources belonging to
  different administrative domains keep on joining and leaving the
  system scheduling must be adaptive.

\item[Heterogeneous providers and services:] There is no single cloud,
  but we have to recognize that the competitive nature in the cloud
  market promotes not only heterogeneous cloud providers, but also
  heterogeneous cloud services that may compete with each other and
  either offer the same or customized services targeting a particular
  user community. Resources in cloud environment are highly
  diversified in nature, capacity, working style and administrative
  domains. Being owned by different organizations, the resources offer
  minimal control over them making multi-layered scheduling necessary,

\item [Highly diversified:] Due to the large diverse set of
  applications (but also infrastructure) smart strategies to schedule
  such applications on the required resources are needed.

\item [Decentralized:] The resources in the cloud are distributed
  among various data centers, rack, and servers. Although they may
  belong to a provider, they can still be utilized across provider
  boundaries and even if within the same provider regions, calling for
  a high degree of decentralization.

\item[Limited control by users:] Due to the fundamental nature of the
  cloud access to low level scheduling mechanisms are often hidden and
  only available to the provider. On the other hand users still have
  their own scheduling requirements in regards to for example cost,
  and deadlines.
  
\item[Dynamic loads:] Due to the size of the user community sporadic
  burst on resource requirements lead to challenges to adjust
  provisioned resources and schedule application onto them.

\item[Security concerns:] Another important requirement for scheduling
  is the ability to integrate issues such as privacy and security
  considerations as the provider needs to assure that local laws as
  well as the general privacy and security concerns are addressed.
  This is especially of concern when government or health care
  providers need to schedule resources in a cloud for their
  application needs, making it necessary to distinguish problems that
  can be executed on public vs private clouds through scheduling but
  also through policy decisions that integrate with scheduling
  algorithms.
  
\end{description}

Thus we need to distinguish a number of scheduling challenges one of
which is governed by on differentiating users and providers. Here, on
the one hand, we focus on cloud providers that try to utilize in the
best possible way the existing resources for the customers under
optimization constraints such as cost, high availability, fault
tolerance for the providing cloud resources and services. On the other
hand, we have customers that expect these quality assurances, but also
have own constraints such as deadlines, cost, and implicit
requirements from their applications such as data placement and
management.

In both cases we need to address the challenge of provisioning
resources and also the challenge of scheduling services onto these
resources. Although these steps can be done independently it is
obvious that interrelationship between them is needed in case of
re-provisioning and dynamic adaptation to dynamic loads placed on the
resources.

In both cases under-utilization prevents a resource from performing
optimally, incurring idle time, whereas over-utilization causes a
resource to function more, thereby, sometimes, degrading the node's
performance.

\input{graph-challenges}


\subsection{Scheduling Challenges Arising form use of Containers}

By using virtualization technologies such as virtual machines, they
help to provide the illusion of a hardware resources but introduce a
cost to also virtualize the operating system. Containers however use
virtualization within the operating system level. Multiple containers
run on the top of the operating system kernel. Hence, a container is a
lightweight approach to implement the virtualization technology
leveraging the underlying OS. The memory consumption by containers is
less then the resources required to boot a virtual machine with its
virtualized OS. As example we point out Kubernetes \cite{Kuber2018}
where containers within a pod \cite{Kubernates2018} share an IP
address and find each other via local host. Communication among them
is done by inter-process communications, such as, SystemV semaphores
or POSIX shared memory. Containers in different pods cannot
communicate directly as they have distinct IP addresses. Kubernetes
commonly uses flannel to accomplish container networking. Containers
are joined in a virtual network. Kubernetes, provides mechanisms to
utilize a number of pre-existing scheduling algorithms, but also
provides the ability to replace them with customized approaches.

The challenge here is to assure that containers between users do not
create security or violate privacy issues. Also the access to
potentially elevated system privileges may cause other issues.
Therefore systems such as Singularity offer users an isolated use of
containers within traditional HPC queuing systems to mitigate that
issue. Still once on such a system, we still have to be aware of
elevated privileges, and containers may only be offered in limited
form to its users. Once this has been clarified, also for containers
the typical quality assertions during its use apply just as for
virtual machines. Such challenges must be integrated into a scheduling
strategy when adding containerized cloud resources.


\subsection{Challenges in Function as a Service}

The {\em Function as a Service} model allows the developers to build
and execute their programs through a combination of functions, that
limit resource requirements. Functions are uploaded to FaaS supporting
infrastructure and services and triggered by events. Due to the
resource limitations they provide significant information for the
underlaying layers to provide more efficient resource scheduling.
However, monitoring tools and fault tolerance have to be carefully
integrated in order to avoid FaaS failures based on resource
starvation or an excess of resources used. In addition more resource
intense functions may require splitting them up in smaller functions
so they can be fulfill resource constraints of the FaaS framework.
Such limitations must be understood by the developer in order not to
create a function that is impossible to schedule.


\subsection{Taxonomy of Scheduling Units}

The traditional units for scheduling include, processes, tasks, and
jobs. However in the cloud we have an enhanced model that needs in
addition to this address scheduling of virtual machines, containers,
functions, platforms, clusters, and other infrastructure or services
used by the clients or cloud related services. Naturally such units
can be abstracted into tasks that are coordinated as part of
workflows. Hence, we distinguish as part of this model the following
units that typically define work units:

\begin{description}

\item[Task:] represents an abstract unit to be run on a cloud that may
  have complex resource association attached with it and may itself be
  build from other tasks with dependencies. It is not yet mapped onto
  a resource.

\item[Job:] A job is a computational activity made up of several tasks
  that may require different processing capabilities.

\item[Function:] represents a small computational unit with precisely
  specified resource requirements to run on a cloud.

\item[Application:] An application is a software for solving a (large)
  problem in a computational infrastructure; it may require splitting
  the computation into many jobs or it may be a monolithic
  application. In the later case, the whole application is allocated
  in a computational node and is usually referred to as application
  deployment.

\item[Workflow:] A workflow contains a combination of Tasks, Jobs,
Functions, and applications with dependencies assuring the order of
execution.

\end{description}

On the other hand we find resources units that are typically
associated with the provisioning step:

\begin{description}

\item[Resource:] A resource is a basic computational entity that can
  be used to fulfill the requirements of application's execution.
  Resources have their own characteristics such as CPU
  characteristics, memory, software, etc. It can be a source of
  information and expertise. Resource is phenomenon that enhances the
  quality of application. Various parameters are associated with a
  resource, among them, the data speed, the processing speed, space
  and workload, which change over time.

\item[Deployment:] A deployment is a series of jobs that deploy a
  service onto the cloud that can be used for subsequent use.

\item[Containers:] can be defined as a any service related to
  scheduling, made available to users on demand from a cloud computing
  provider's servers.

\item[Virtual machine:] Virtual Machine (VM) is a simple software
  program which simulates the functions of a physical machine.

\item[Virtual clusters:] An agglomeration of virtual services that
  build the core of a computational resource hosted in the cloud. They
  can be comprised out of many resources including virtual machines,
  containers, platform as a service frameworks, data services and
  resources, and more. A virtual cluster is typically associated with
  an application and utilized for it. Just as containers or virtual
  machines it can be created, suspended, resumed, or terminated

\item[Schedulers:] Schedulers are processes that decide which task and
  process should be accessed and run at what time by the available
  resources. It helps to keep the performance of cloud at the highest
  level by scheduling in optimized way. Based on the frequency of
  schedulers operations, categorization is done: local scheduler,
  global scheduler and enterprise scheduler etc.

\end{description}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Taxonomy Classification of Resource Scheduling Algorithms}\label{S:algo}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Next we present a short sample on resource scheduling algorithms that
we found in literature related to cloud computing scheduling as
showcased in Figure~\ref{F:class-scheduling1221}. We present in the
figure only a relevant subset of algorithm classifications including
the distinction between VM placement and QoS parameters based
algorithms. Dependent on the locality and scope of the scheduling task
often a deterministic approach is not suitable. When looking at
heuristics \cite{vivekanandan2011study} we find traditional algorithms
such as hill-climbing but also a variety of nature inspired
algorithms. The detail description of existing work in the field of
resource scheduling algorithm is done in the next section.

\input{graph-algorithms}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Literature review of Cloud Resource Scheduling Algorithms}\label{sec:literature}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



In this section we conduct an exemplary but extensive literature
review of cloud scheduling in order to confirm our taxonomy. As part
of this review, we present a number of tables to compare the reviewed
research and frameworks related to cloud scheduling.

We organize this section by scheduling aspects related to 

dynamic scheduling (Section~\ref{sec:dynamic})
cloud metric based scheduling with emphasize (Section~\ref{sec:vm-scheduling}) on 
energy (Section~\ref{sec:energy})
network (Section~\ref{sec:network})
cost (Section~\ref{sec:cost})
time (Section~\ref{sec:time})
reliability (Section~\ref{sec:reliability})
security (Section~\ref{sec:security}),
and heuristics (Section~\ref{sec:heuristic}).

We review scheduling needs for 
HPC in the cloud (Section~\ref{sec:hpc}) and 
workflows (Section~\ref{sec:workflow}).

We mention scheduling in public clouds (Section~\ref{sec:public})
while also looking at containers (Section~\ref{sec:container}),
function as a service (Section~\ref{sec:faas}) as well as distributed
resource providers (Section~\ref{sec:distributed}) which can utilize
service meshs (Section~\ref{sec:mesh}).





\subsection{Dynamic Scheduling}\label{sec:dynamic}



As part of this scheduling task we often also find the distinction
between static scheduling, where resources are scheduled once,
~\cite{jennings2015resource} and dynamic scheduling, which is
constantly updated during execution to find better resource
utilization over time. The later is often motivated by need for
scalability~\cite{keller2014hierarchical} across and within data
centers or increased fault
tolerance~\cite{tighe2013distributed}. Association of other metrics
into the dynamic scheduling approach is common to for example
integrate power, reduce network bandwidth and enable more
sophisticated Service level agreements~\cite{tighe2013distributed}. In
many cases not only the cloud user, but obviously also the cloud
provider can benefit from dynamic
scheduling~\cite{tighe2014integrating}. We find that it can be
beneficial to separate the scheduling task in multiple steps such as
shown in~\cite{sun2015live}. Here live migration for correlated VMs is
optimizing on data, compute, and bandwidth. Other cloud metrics such
as price~\cite{tordsson2012cloud} are also common and will be in more
detail addressed in Section ~\ref{sec:cost}. Obviously a rich number
of algorithm can be applied such as shown in
Section~\ref{sec:heuristic}.

Table~\ref{T:dynamic-scheduling} lists a number of efforts related to
dynamic scheduling while focusing on virtual machine placement.


\input{table-dynamic-placement}



\subsection{Cloud Metric-based Scheduling}\label{sec:vm-scheduling}



Due to the complexity of cloud environments, many different metrics
are used to guide the scheduling of virtual machines, containers,
platforms, tasks, batch jobs and
workflows. Figure~\ref{F:class-scheduling1221} showcases many
different metrics that influence their schedule.  


\subsubsection{Energy Aware Scheduling}\label{sec:energy}



Energy consumption is a key issue for cloud providers due to the
enormous cost associated with operating large cloud data center. By
using server consolidation, optimizing operation on physical machines
and using dynamic voltage scaling processors, energy consumption can
be reduced as shown in \cite{las09dvfs,las10dvfs,calheiros2014energy}.

Various scheduling methods such as minimize the total
makespan~\cite{bessis2013using}, dynamic
meta-heuristic~\cite{bi2017application}, fractal
mathematics~\cite{duan2016energy}, and machine learning clustering and
stochastic~\cite{bui2016energy} have been utilized.


It is obvious that multiple metrics must be included the correlate for
example CPU, RAM and bandwidth~\cite{zhu2017three}. Dynamicity, for
example, while addressing peak loads~\cite{duan2016energy} or
migration~\cite{beloglazov2010energy} has naturally also an impact on
the energy cost. Energy in hybrid and multiple data centers in the
clouds is used
in~\cite{quarati2013hybrid,garg2011environment,gai2016dynamic} while
at the same time increasing the cloud provider brokers revenue. Energy
consumption in heterogeneous clouds has also been
considered~\cite{ding2015energy}.  Others create models to predict the
energy consumption of each virtual machine~\cite{kim2014energy} this
requires certainly proper monitoring of the underlying server farms in
the cloud in~\cite{van2012comparison}. Integration of historical or
previous program executions while recording their energy consumption
can also be utilized~\cite{hu2010scheduling}. Others focus on
predicting future resource consumption needs~\cite{dabbagh2015energy}.






A comparison of energy aware scheduling algorithm in cloud computing is shown in
Table~\ref{T:g}.



\input{table-energy}

\subsubsection{Network Aware Scheduling}\label{sec:network}




As clouds project remote large scale resources network traffic to,
from, and within must be considered for scheduling. This not only
contains moving data in and out of the compute center or storage, but
also may contain message exchange between to sometime complex
distributed applications that run in these cloud data
centers. Minimizing the distance between data providers and data
consumers while for example replicating data \cite{www-akamai} can save
significant amount of traffic and has long been applied in the
internet as one of its beneficial strategies. Service level agreements
(SLA)~\cite{breitgand2012improving} are playing an important role to
achieve proper utilization as part of the scheduling effort. Treating
the network as shared scarce resource~\cite{rampersaud2016sharing}
motivates the development of network-based scheduling algorithms.
Just as in other metric-based scheduling models, we find the
distingtion between static~\cite{biran2012stable} and dynamic
scheduling during runtime so we can deal with traffic bursts.

A variety of resource abstractions (see Figure~\ref{F:class-metric}) are
applicable also to scheduling as part of the network traffic, such as
demonstrated by~\cite{yu2017survivable} to optimize traffic in virtual
clusters.  Scheduling across on multiple layers is especially of
benefit for networking~\cite{bi2015sla} to minimize across different
tiers.  Scheduling of platforms such as Hadoop offers naturally
advantages when networking is integrated~\cite{kondikoppa2012network}.  Having access to lower level infrastructure
such as offered by OpenStack presents opportunities to include Network
Function Virtualization (NVF)~\cite{lucrezia2015introducing}

Table \ref{T:c} shows examples for network aware scheduling algorithms
in cloud computing.



\input{table-network}


\subsubsection{Cost Aware Scheduling}\label{sec:cost}



Cost in clouds arise for using the data center facilities. These costs
are passed along to the users. Through shared use of the facilities
and keeping under-utilization low, clouds can have an advantageous
cost performance in regards to on-premise compute and data
centers. Costs for such centers include hardware operation cost such
as energy and equipment, as well as, operating costs such as software
licensing and update and personnel costs. Dependent on the hardware
and software used, cloud providers offer a tiered cost model that
allows users to assess need for data, speed, and reliability as part
of their cost.  Other options such as renewable energy use of the data
center in case of energy aware customers may also play a role.

Cost aware scheduling has been applied to virtual
machines~\cite{yuan2017ttsa},
tasks~\cite{yuan2017temporal,zuo2015multi},
workflows~\cite{arabnejad2015cost,arabnejad2016budget}, as well as
high-throughput~\cite{yuan2016cawsac} computing.  Revenue
maximization~\cite{yuan2018warm} has not only been applied to metrics
such as latency~\cite{ghahramani2017toward}, but is also useful via
advanced dynamic Voltage and Frequency Scaling
(DVFS)~\cite{las10cloudsched,calheiros2014energy} due do reducing the
high energy costs with little performance reduction. This also could
be achieved through delayed execution~\cite{bi2016trs} or relaxation
of deadlines~\cite{zhang2018dynamic}.  Other strategies include the
introduction of penalties as part of SLA~\cite{wu2012sla}. Typical
resource utilization such as optimizing processor
sharing~\cite{lee2012profit} data placements~\cite{lee2012profit},
have known to decrease cost. Obviously also dynamic dynamic
adaptations at runtime allow reduction of cost~\cite{ari2013design}

Table \ref{T:e} presents a comparison of cost aware scheduling algorithms.



\input{table-cost}

\subsubsection{Time based Scheduling}\label{sec:time}



Cloud users have the desire to reduce the time it takes to execute
their applications. This is often motivated to fulfill
deadlines~\cite{arabnejad2017scheduling}.

Besides virtual machine and task scheduling it is also important to
integrate data-aware scheduling to reduce access time to the
data~\cite{van2013online}. As already mentioned previously, historical
data~\cite{thomas2015credit} or proxies~ \cite{erdil2013autonomic}
about execution times help designing time-aware scheduling algorithms.

We find algorithms that integrate
deadline constraint ~\cite{li2016energy}, 
completion time~\cite{xu2011job} with fairness~\cite{jasso1989theory}, 
low downtime to improve time for execution~\cite{frincu2014scheduling},
and 
delay bounds 
~\cite{yuan2018time}.

Table~\ref{T:f} presents a comparison of time aware
scheduling algorithms.

\input{table-time}

\subsubsection{Reliability Aware Scheduling}\label{sec:reliability}



Users and providers need the guarantee of reliability. Thus many
scheduling efforts integrate how to increase reliability. Strategies
such as replication of data and compute services are common
practice. Obviously this comes often at a price and increased cost may
occur when reliability is concerned. The distributed nature of clouds
make it a formidable challenge to offer reliability. However at the
same time while providing large scale data centers to offer cloud
services with highly specialized operating staff and abilities to
replicate and migrate workloads to other services increases
reliability when compared to on-premise data centers due to larger
efficiency of the cloud data centers in regards to overall cost for
its users.

Various studies have been conducted to analyze the effect of reliability on clouds.

This includes reliability assessment models
~\cite{malik2012reliability}, integration of communication and
networks~\cite{jing2015reliability}, increase of resource
availability~\cite{latiff2016fault}. Trade offs between different
scheduling metrics such as energy and reliability have also been
studied~\cite{tang2016energy}.

A comparison of reliability and scheduling is given in Table~\ref{T:h}.



\input{table-reliability}

\subsubsection{Security based Scheduling}\label{sec:security}



As mentioned earlier security as a key aspect cloud users and
providers require in order for cloud infrastructure to be useful for
many applications.

Virtual machine scheduling requires the need for isolation, that can
be controlled by security
policies~\cite{afoulki2011security}. Isolation can also apply to the
incoming and outgoing data~\cite{chejerla2017qos,kashyap2014security}.
Risks occurring by inspecting the connections among VMs
~\cite{shetty2016security} can be analyzed and integrated in
scheduling strategies.  To enable trust between components in the
cloud background key exchanges have been proposed~\cite{liu2013ccbke}
Multi-objectives (possibly contradictory) need to be also
considered. Most often it includes cost vs. security scheduling
frameworks~\cite{kashyap2014security,zeng2015saba,wang2012cloud}.  As
many edge devices need to interface with cloud services due to their
computational and data limitations, privacy-preserving solutions to
interface between clouds and mobile devices have been considered
~\cite{bilogrevic2011meetings}.

Security based scheduling algorithms are presented (see
Table~\ref{T:i}). 



\input{table-security}

\subsection{Heuristic based Scheduling}\label{sec:heuristic}



Heuristic methods help to design efficient algorithm to fulfill the
users application requirements. We provide here a small sample of
different heuristics as found in literature. This includes particle
swarm optimization~\cite{pandey2010particle}, multi-objective genetic
algorithm-based ~\cite{mezmaz2011parallel,gkasior2016metaheuristic},
colony optimization with swarm intelligence~\cite{mateos2013aco}, bee
colony~\cite{ld2013honey}, artificial neural
networks~\cite{kousiouris2011effects}, simulated
annealing~\cite{torabzadeh2010cloud},
game-theory~\cite{gkasior2016metaheuristic}, and Game theory by
minimizing the Pareto dominance and makespan~\cite{su2013cost}.  Other
heuristics utilize classical models such as using the critical path in
multi-phase scheduling algorithms ~\cite
{abrishami2013deadline}. Besides virtual machines we often also find
workflows to be the scheduling unit in
heuristics~\cite{bousselmi2016qos}.

A comparison of heuristic methods based scheduling
algorithm is done in Table~\ref{T:j}.



\input{table-heuristic}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% HPC AND CLOUD
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{HPC and Cloud Computing Scheduling}
\label{sec:hpc}


Next we review scheduling aspects related to traditional High
Performance Computing (HPC). It is important to recognize, that HPC
and its frameworks must not be excluded as part of cloud scheduling
due to its exposure for scientific application in industry and
academia. More importantly HPC is now also offered as one of the supported
compute services in public cloud providers. When looking at the services offered
and needed we distinguish HPC batch queuing in the cloud, cloud
bursting of on premise HPC tasks, container isolation, on demand
platforms and bare metal provisioning.

\begin{description}

\item[HPC Batch Queuing in the Cloud.] These are specialized
  high-performance super-computing systems that are offered to
  customers with computation needs that can only be fulfilled by large
  scale specialized hardware. Grand challenge problems are often
  motivators for such hardware. In industry we for example find
  computational fluid dynamics, and modeling of biochemical processes
  as one of its user communities. Example offerings for HPC in AWS
  \cite{www-aws-hpc}, Azure \cite{www-azure-hpc}, Google \cite{www-google-hpc},
  but also other less prominent clouds such as Penguin Computing HPC
  in the cloud~\cite{PODHPCCloud2019}, and
  SabalCore~\cite{Sabalcore2019}.
  
\item[Cloud Bursting of On Premise HPC tasks.] The HPC systems are
  often over-utilized and thus the situation of resource starvation is
  to be considered. For this reason many batch queuing system allow
  the integration of cloud resources in such a fashion that task and
  workflows may be executed in the cloud through the integration of
  commercial or on premise cloud resources. In this case the term
  cloud bursting is used
  \cite{CloudBursting2019,BurstingHPC2019}. Example for the
  integration in prominent HPC scheduling includes Slurm~\cite{www-slurm},
  Univa Grid Engine~\cite{www-univa}, PBSpro~\cite{www-pbs-manual}, LSF~\cite{www-lsf-job-dep},
  Moab~\cite{www-moab-job-dep}.

\item[Container Isolation.] Due to the usage of queuing systems it is
  also possible to provide in part an improved container security
  framework, while executing containerized tasks as part of the
  queuing system. An example would be to utilize all cores in a
  compute server that is allocated with a queuing system
  processor. This feature can be integrated into many queuing systems
  while using Singularity~\cite{www-singularity}.

\item[On Demand Platforms.] Resource starvation in academic cloud and
  super computing centers motivate also the ability to run platforms
  that would typically run also in the cloud but provide a cheaper
  alternative if run locally in the existing HPC centers. A good
  example is Hadoop that can be run through
  myhadoop~\cite{krishnan2011myhadoop} in HPC centers~\cite{SDSC2019}.

\item[Bare Metal Provisioning.] In other cases it may be better to
  provide bare metal provisioning capabilities in case the
  existing platform or cloud abstraction may not be sufficient.
  Academic efforts such as Futuregrid~\cite{fox2013futuregrid} now
  followed by Comet~\cite{las-comet} and Chaleleoncloud~\cite{Chameleoncloud2019} 
  are good examples for it. Commercial
  efforts in this regard include OpenStack Ironic
 ~\cite{OpenstackIronic2019}, IBM~\cite{IBMBareMetal2019}, AWS
 ~\cite{AWS2019} and Rackspace~\cite{Rackspace2019}.

\end{description}


\input{table-batch}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% WORkflow
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{Workflow Scheduling Frameworks} 
\label{sec:workflow}



In the previous sections we already pointed out several workflow
related scheduling algorithms while using specific metrics to conduct
the scheduling. In addition we can integrate virtual machines,
containers, and tasks.

Workflow schedulers are often distinguished by
DAG~\cite{deelman2005pegasus,deelman2004pegasus,thain2005distributed}
and non-DAG scheduling while some support
both~\cite{las-karajan,las-cogkit-1,las06-workflow-book}. Even prior
to the official FaaS frameworks existed that focused on the execution
of functions~\cite{las-infogram}.  Scientific applications such as
bio-informatics have introduced not only workflow systems, but also
promoted graphical workflow design tools to create dependency graphs
the are executed by workflow
schedulers~\cite{oinn2004taverna,tan2010comparison}.
  
In addition to our findings, in~\cite{yu2005taxonomy} workflows are
also organized by design, scheduling and data movement abilities.

It is often an overlooked fact that existing HPC batch queuing systems
contain features for job dependency management. In many cases these
features can be used to accommodate the users needs for scheduling
workflows onto the same hardware or in some cases clusters that are
managed through the same queuing
system~\cite{www-lsf-job-dep,www-moab-job-dep,www-univa-GE-manual,www-pbs-manual}.



\subsection{Scheduling in Public Cloud Providers}
\label{sec:public}



Next, we compare scheduling methods and needs offered in public cloud
service providers are presented. This includes AWS, Azure, Google,
Rackspace, but also academic clouds such as FutureGrid and
FutureSystems Comet, Jetstream, and Chameleon Cloud.

It is important to recognize that today public cloud providers offer
not only virtual machines to the users, but a large variety of
compute, data, and analytical services. Some of them may even use bare
metal while others are having heightened security demands to for
example fulfill heath care or government isolation needs as part of
the infrastructure. All these aspects naturally influence the
scheduling efforts which need to be addressed by the provider. In many
cases we do not find some of the information on how such scheduling is
conducted due to security and company secrets.

However we find metrics that users can utilize to formulate their own
strategies as we have introduced in the previous section if such
metrics are communicated to the users. This typically includes cost
and allows to leverage for example virtual machine with reliability
constraints such as AWS spot pricing compared to regular
pricing~\cite{AmazonEC22015}.  Cost also motivates users to suspend
usage of VMs instead of running them without concern. This has
happened to the authors of this paper, where in a class a student,
refused to shutdown experimental virtual machines and within two weeks
consumed thousands of compute hours on an academic cloud, while the
actual calculation was irrelevant.

One of the schedulers provided by public clouds are job and instance
schedulers that promote start and stop times for the resources
used~\cite{AWSIns2019,AzureSch2019,Rackspace2016,GoogleAppEngine2018}. Such
schedulers can integrate functions, data and compute instances. More
sophisticated schedulers can switch workloads between cloud data
centers~\cite{MicrosoftAzure2014}.

In ~\cite{Rackspace2016} cloud load-balancer, round robin and least
connections based algorithms are commonly used so that workload could
be distributed equally on all resources.  As one of the original tasks
of clouds was hosting of Web services under traffic load. public
clouds include strategies the scale up and down the services based on
such loads and allocate dynamically through a scheduler resources to
fulfill this demand.

Other providers have focused on making use of multicloud virtual
machine placement possible while offering optimization strategies for
workflows~\cite{CloudSigma2016} including detailed analysis of cost
metrics \cite{Cloudmetrics2019}

Other efforts such as~\cite{las12fg-bookchapter,fox2013futuregrid}
have early on uniquely focused on scheduling bare metal resources
between the use of HPC and clouds, while running HPC queuing systems
on the same resources as cloud resources. Dynamic provisioning allowed
resources to be provisioned to the one or the other by
demand. In~\cite{las-comet} the re-provisioning is even done with the
help of a traditional batch queuing system.

Table~\ref{T:iaas} depicts examples as used in public cloud providers.



\input{table-iaas}


\subsection{Scheduling in Container Frameworks}
\label{sec:container}


Container schedulers provide mechanisms to fine-tune the selection
processes of containers onto distributed
resources~\cite{Containers2018,de2018distributed}. Typically a default
default scheduling policy is provided. Policies might place new
services on hosts with the fewest currently active services.

Based on our Y-diagram we need to distinguish 2 different
services. First, scheduling on the same server and second scheduling
on a number of servers that are treated typically as one abstract
resource.

For the first scheduling task we need to consider data management to
efficiently utilize the memory hierarchy, but also for example
execution deadlines or privacy concerns to organize the computation
tasks as required. In the distributed case we also need to integrate
communication related aspects. We focus next on the distributed
frameworks in more detail we focus on Docker Swarm, Kubernetes,
Singularity, and Mesos.

\begin{description}


\item[Docker Swarm.] Docker Swarm is a clustering and scheduling
tool for Docker containers \cite{Dockerswarmengine2018} across compute
servers. In a docker swarm we distinguish manager nodes and worker
nodes. The manager uses load balancing to place the containers onto
the worker nodes. Once a task is placed on a server it is executed
there.  Docker swarm uses a single scheduling
strategy~\cite{Dockerswarm2018}.



\item[Kubernetes.] Kubernetes is an open-source orchestrator
developed by Google for automating container management and
deployment~\cite{Kubernates2018}. The basic deploy-able object is a
Pod which consists of one or more containers running in a shared
context. An API is used to declare policies and scalability
constraints. The Kubernetes scheduler is topology aware and workload
aware which can be integrated into the policy policy constraints to
expose availability, performance and capacity. Auto-scaling, load
balancing and secrets managements are also provided by Kubernetes.

\item[Singularity.] Singularity can be using a variety of
container frameworks as backend. It allows the use of containers
without being superuser. Due to this, singularity is a popular choice
for running containers on traditional HPC
systems~\cite{www-singularity}. Due to this scheduling can be
supported directly by the under-laying queuing system.


\item[Mesos.] Mesos~\cite{hindman2011mesos,Mesos2018} provides an
API for resource management and scheduling in data centers. Mesos
abstracts CPU, memory, storage, and other compute resources. It
integrates fault-tolerance. Mesos provides a thin resource sharing
layer that helps to furnish fine-grained sharing by providing common
interfaces among different cluster frameworks. It's goal is improved
utilization, respond quickly to workload changes, by maintaining
system's capability in terms of scalability and robustness.


\item[Community Efforts.] Many community efforts to improve
container scheduling are conducted. This includes for example the use
of genetic algorithm~\cite{guerrero2018genetic}, container and host
selection policies for cloud deployment models \cite{hanafy2017novel}
with SLA's, the characterization of
applications~\cite{medel2017client} scheduling of virtual
clusters~\cite{dziurzanskivalue}, and migration~\cite{Flocker2018},
and systems integrating multiple schedulers such as Nomad which offer
service scheduler, batch scheduler and a systems scheduler while
focusing on the support of long running jobs \cite{Nomad2018}.  
\end{description}
Table ~\ref{T:z} shows the comparison of existing work related to scheduling. 




\input{table-container}






\subsection{Function Scheduling Algorithms}
\label{sec:faas}



To further improve scheduling on cloud resources, the concept of
function as a services was introduced.  It allows the invocation of
small functions with limited resource constraints on
servers~\cite{lasbook}. For example a minimum execution time per
request is five minutes provided by AWS lambda and azure
functions~\cite{ServerlessComputing2018}. It supports manage user
defined functions on highly available infrastructure in an unified
manner~\cite{nastic2017serverless}. This also allows the scheduling of
workflows comprised out of
functions~\cite{alqaryouti2018serverless}. In~\cite{fox2017status} we
discuss the status of serverless computing and function as a service
in Industry and research.  Serverless computing is considered the
backend for running FaaS at runtime. System allocation and other
resource management activities are provided by the backend. Thus the
users has not to worry about activities conducted by the
server. Hence, the name serverless computing. Through the use of FaaS
and serverless computing cost can be reduced by more efficiently
scheduling smaller tasks on resources.

A number of FaaS frameworks exist that can be used on public clouds
but also self hosted clouds or network of workstations.

Scheduling in FaaS is provided by triggers. Such triggers offer a
publish subscribe model in which events are conducted, once the
trigger is fired. This includes triggers for time, data, and
executions. Time based scheduling is supported by cron.  These
frameworks are supported by all major public clouds including AWS
lambda~\cite{AWSlambda2018}, Google cloud
functions~\cite{GoogleCF2018}, Azure Function~\cite{Azure2018}

Other open source frameworks such as Apache
OpenWhisk~\cite{OpenWhisk2018} allow users to install FaaS services on
their own infrastructure.


\subsection{Scheduling among Distributed Resources and Providers}
\label{sec:distributed}





Users may have the desire to not only use services on one cloud but on
multiple clouds. This is motivated largely by avoiding vendor lock-in,
unique service offerings, or combining services from different
vendors.

\input{table-distr-cloud}

Such efforts contain Eagle, a hybrid data center scheduler for
data-parallel programs~\cite{delgado2016job};
Hopper~\cite{ren2015hopper}, a job scheduler that trades off existing
and speculated job scheduling decisions; Tetris
~\cite{grandl2015multi}, a cluster scheduler that aims to match
multi-resource task requirements with resource availability;
Fawkes~\cite{ghit2014balanced} a multi-cluster systems for map-reduce;
Omega~\cite{schwarzkopf2013omega} with optimistic concurrency control;
OurGrid~\cite{andrade2003ourgrid,cirne2006labs} for worldwide
computing platform with isolated environments;
Sparrow~\cite{ousterhout2013sparrow} and fine-grained task scheduling
scheduler.
  
We can also find more prominent schedulers such a contains Apache's
  Hadoop YARN~\cite{vavilapalli2013apache} which acts as a resource
  management systems to for example schedule Hadoop distributed
  processing framework considering QoS, scalability, higher efficiency
  and fair resource usage.

We contrast different resource management systems, used for
maintaining resources in distributed environments such as Clouds (see
Table \label{T:distr-cloud}).

\subsection{Service Meshups} 
\label{sec:mesh}

To support scheduling across clouds and services, service mashups can
  be used. This includes long standing efforts such as Cloudmesh,
  which targets the creation of reproducable environments to easily
  manage virtual machines, bare metal provisioned operating systems,
  platform deployments and more recently data services in a
  multi-cloud environment. It is a goal to integrate custom schedulers
  in such service mashups. Another example is
  Terraform~\cite{www-terraform} which focuses on reproducible
  environments.




%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Conclusion and Lessons Learned}\label{sec:conclusion}



In this section we summarize some of the lessons we learned from our activities.

\begin{description}

\item[More than VM scheduling.] Due to the shift and enhancement of
clouds from VM to containers and FaaS, we must consider also new
scheduling strategies as motivated by thes new cloud compute
offerings.

\item[Integration for data.] Big Data and management of data in
general motivate the integration of data resources as firs class
activity within scheduling.

\item[Energy.] Energy costs for data centers are enormous and this
play a significant roll for providers, but also for users to which
energy cost are passed along. Not only good scheduling algorithms are
needed, but the design of the data center close to cheap energy is an
important aspect.

\item[Y-Diagram.] Our Y-diagram promotes scheduling across scale and
models. This allows to create hierarchy of interfacing scheduling
approaches for integrated and layered scheduling between resources at
different scales.

\item[Multi-Metric and Multi-Objectivity.] Scheduling algorithms must
use multiple metrics and multiple objectives to provide effective
scheduling decisions. In many cases contradictory scheduling goals
such as reliability vs cost are to be considered.

\item[Policy driven.] Due to multi-metric and multi-objective
scheduling goals modern schedulers will expose them through policies
to users and providers.


\item[Iterative Optimization in Layers.] Due to the complexity of the
scheduling efforts motivated by out Y-diagarm, a layered scheduling
approach seems appropriate.

\item[Analytics Services.] While FaaS provide the ability to schedule
resource restricted functions the next level of schedulers will
address Analytics as a Service (AaaS) where more resource bound
functions are cast as analytical calculations.

\item[Security and Privacy.]  We need to deal more stringently with
security and privacy as part of our scheduling needs which contrasts
traditional HPC scheduling efforts.

\item[Fault tolerance and Risk Analysis.] As part of the policy driven
service level agreements with the cloud providers scheduling must
include the ability to integrate fault tolerance while leveraging risk
analysis.

\item[Traditional Scheduling.] Naturally we need to deal in scheduling
with traditional issues such as load balancing, congestion, and
service spikes. However they are amplified by the large resource
management issues in hyper-scale data centers.

\item[Edge Computing and Fog computing.] Due to the increased edge and
Fog computing computational powers available. significant activities
can also be conducted on edge devices. Billions of cellphones today
already conduct a significant amount of computation thus scheduling
must balance between activities that can take place on the edge (Fog)
or needs to be conducted in the cloud.

\end{description}


In this paper, we have surveyed the many important aspects of
scheduling problems in cloud computing. After introducing the needed
terminology, we presented a comprehensive taxonomy of the different
cloud scheduling approaches and issues. A layered and phased
scheduling model is presented that differentiates the concerns between
infrastructure, platform, servers and function as a service models. A
comprehensive investigation has been conducted to verify that the
taxonomy is valid and that existing scheduling techniques motivate its
validity.










\appendix

\section{Postface}

We realize that although we have analyzed a large number of papers,
there are more papers in that area available. Please inform us as we<
intend to collect them for further updates to this paper. We like to
especially pay attention to papers that may motivate us to refine our
taxonomy. Please send us your reference in \BibTeX format while adding
in the abstract what your paper provides and how it fits in our
scheduling taxonomy. The contribution can be send either to
\verb|laszewski@gmail.com|, or via a github pull request at
\url{https://github.com/cloudmesh/bib/blob/master/cloud-scheduling.bib}.



%
% BIB
%

\bibliographystyle{elsarticle-num}

\bibliography{strings,cloud-scheduling,vonlaszewski}


\end{document}
